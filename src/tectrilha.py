import requests
import pandas as pd
import sqlite3
from time import sleep, time
import os
from datetime import datetime
from urllib.parse import urlparse
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def normalizar_url(url):
    url = url.strip()
    if not url.startswith('http'):
        url = 'https://' + url.strip().lstrip('/')
    return url.rstrip('/')

def get_retry_session():
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=2, status_forcelist=[500, 502, 503, 504])
    session.mount('http://', HTTPAdapter(max_retries=retries))
    session.mount('https://', HTTPAdapter(max_retries=retries))
    
    # Adiciona um cabeÃ§alho padrÃ£o de navegador
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'
    })
    
    return session


def main():
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_dir = os.path.join(base_dir, 'data')
    bds_dir = os.path.join(base_dir, 'bds')
    logs_dir = os.path.join(base_dir, 'logs')

    assuntos_file = os.path.join(data_dir, 'assuntos_tectrilha.csv')  # Agora usamos o CSV de assuntos
    prefeituras_file = os.path.join(data_dir, 'prefeituras.csv')
    db_file = os.path.join(bds_dir, 'tectrilha.db')
    error_log_file = os.path.join(logs_dir, 'tectrilha_errors.log')
    execution_log_file = os.path.join(logs_dir, 'tectrilha_execution.log')
    last_run_file = os.path.join(logs_dir, 'tectrilha_last_run.txt')

    os.makedirs(bds_dir, exist_ok=True)
    os.makedirs(logs_dir, exist_ok=True)

    while True:
        print("\n" + "="*50)
        print("MENU PRINCIPAL - TECTRILHA DATA EXTRACTOR")
        print("="*50)
        print("1. Rodar cÃ³digo para um perÃ­odo especÃ­fico")
        print("2. Rodar URLs que falharam (do arquivo de log)")
        print("3. Continuar extraÃ§Ã£o desde o Ãºltimo ano")
        print("4. Sair")

        choice = input("\nEscolha uma opÃ§Ã£o (1-4): ")

        if choice == '1':
            start_time = time()
            log_execution(execution_log_file, "OpÃ§Ã£o 1: Rodar cÃ³digo para perÃ­odo especÃ­fico")
            ano_inicio, ano_fim = get_periodo_usuario()
            run_extraction(ano_inicio, ano_fim, assuntos_file, prefeituras_file, db_file, error_log_file)
            save_last_run(last_run_file, ano_fim)
            log_execution_time(execution_log_file, start_time)

        elif choice == '2':
            start_time = time()
            log_execution(execution_log_file, "OpÃ§Ã£o 2: Rodar URLs que falharam")
            run_failed_urls(error_log_file, assuntos_file, prefeituras_file, db_file)
            log_execution_time(execution_log_file, start_time)

        elif choice == '3':
            start_time = time()
            log_execution(execution_log_file, "OpÃ§Ã£o 3: Continuar desde Ãºltimo ano")
            last_year = get_last_run(last_run_file)
            if last_year is None:
                print("\nğŸ”´ Nenhuma execuÃ§Ã£o anterior encontrada. Use a opÃ§Ã£o 1 primeiro.")
                continue

            current_year = datetime.now().year
            run_extraction(last_year + 1, current_year, assuntos_file, prefeituras_file, db_file, error_log_file)
            save_last_run(last_run_file, current_year)
            log_execution_time(execution_log_file, start_time)

        elif choice == '4':
            print("\nSaindo...")
            break

        else:
            print("\nğŸ”´ OpÃ§Ã£o invÃ¡lida. Tente novamente.")

def get_periodo_usuario():
    print("\n" + "="*50)
    print("DEFINIR PERÃODO DE EXTRAÃ‡ÃƒO")
    print("="*50)

    while True:
        try:
            ano_inicio = int(input("Ano inicial (AAAA): "))
            ano_fim = int(input("Ano final (AAAA): "))

            if ano_inicio > ano_fim:
                print("ğŸ”´ Ano inicial deve ser anterior ou igual ao ano final. Tente novamente.")
                continue

            current_year = datetime.now().year
            if ano_inicio < 2000 or ano_inicio > current_year or ano_fim < 2000 or ano_fim > current_year:
                print(f"ğŸ”´ Ano invÃ¡lido. Deve ser entre 2000 e {current_year}. Tente novamente.")
                continue

            return ano_inicio, ano_fim

        except ValueError:
            print("ğŸ”´ Formato invÃ¡lido. Use AAAA (ex: 2024). Tente novamente.")

def run_extraction(ano_inicio, ano_fim, assuntos_file, prefeituras_file, db_file, error_log_file):
    assuntos = load_assuntos(assuntos_file)  # Carrega os assuntos e parÃ¢metros do CSV
    prefeituras = load_prefeituras(prefeituras_file)
    prefeituras_tectrilha = prefeituras[prefeituras['empresa'] == 'tectrilha']

    if prefeituras_tectrilha.empty:
        print("\nğŸ”´ Nenhuma prefeitura com empresa 'tectrilha' encontrada.")
        return

    session = get_retry_session()
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()

    for _, assunto in assuntos.iterrows():
        endpoint_name = assunto['assunto']
        parametros = assunto['parametros'].strip() if pd.notna(assunto['parametros']) else ""
        
        print(f"\n{'='*50}\nğŸ”§ Processando endpoint: {endpoint_name}")

        cursor.execute(f'''
            CREATE TABLE IF NOT EXISTS {endpoint_name} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                municipio TEXT,
                prefeitura TEXT,
                unidadegestora TEXT,
                ano INTEGER
            )
        ''')
        conn.commit()

        for _, prefeitura in prefeituras_tectrilha.iterrows():
            municipio = prefeitura['municipio']
            prefeitura_nome = prefeitura['prefeitura']
            unidade_gestora = str(int(prefeitura['unidadegestora']))
            base_url = normalizar_url(prefeitura['url']).rstrip('/api')
            print(f"\nğŸ›ï¸ Prefeitura: {prefeitura_nome} ({municipio}) - UG: {unidade_gestora}")

            for ano in range(ano_inicio, ano_fim + 1):
                print(f"ğŸ“… {ano}", end=' ', flush=True)
                cursor.execute(f'''
                    SELECT 1 FROM {endpoint_name} 
                    WHERE municipio = ? AND prefeitura = ? AND unidadegestora = ? AND ano = ?
                    LIMIT 1
                ''', (municipio, prefeitura_nome, unidade_gestora, ano))

                if cursor.fetchone():
                    print("âœ… JÃ¡ existe no BD", end=' ')
                    continue

                # Substitui os placeholders nos parÃ¢metros
                url_params = parametros.format(
                    unidadeGestoraId=unidade_gestora,
                    exercicio=ano,
                    periodo=""
                ).strip()

                # Remove espaÃ§os em branco e adiciona '?' se houver parÃ¢metros
                if url_params:
                    if not url_params.startswith('?'):
                        url_params = '?' + url_params
                    url_params = url_params.replace(' ', '')

                url = f"{base_url}/api/{endpoint_name}{url_params}"
                try:
                    response = session.get(url, timeout=30)
                    response.raise_for_status()
                    if not response.content.strip():
                        print("ğŸŸ¡ Resposta vazia. Ignorando.", end=' ')
                        continue
                    dados = response.json()
                    df = pd.DataFrame(dados)

                    if not df.empty:
                        # Remove colunas que jÃ¡ existem para evitar conflito
                        df = df.drop(columns=['municipio', 'prefeitura', 'unidadegestora', 'ano'], errors='ignore')

                        # Adiciona colunas fixas manualmente
                        df['municipio'] = municipio
                        df['prefeitura'] = prefeitura_nome
                        df['unidadegestora'] = unidade_gestora
                        df['ano'] = ano

                        cursor.execute(f"PRAGMA table_info({endpoint_name})")
                        existing_columns = [col[1] for col in cursor.fetchall()]

                        for column in df.columns:
                            if column.lower() not in [col.lower() for col in existing_columns] and column != 'id':
                                col_type = 'TEXT'
                                if pd.api.types.is_numeric_dtype(df[column]):
                                    col_type = 'REAL'
                                elif pd.api.types.is_integer_dtype(df[column]):
                                    col_type = 'INTEGER'
                                cursor.execute(f"ALTER TABLE {endpoint_name} ADD COLUMN {column} {col_type}")
                                conn.commit()

                        df.to_sql(endpoint_name, conn, if_exists='append', index=False)
                        print("âœ… Dados salvos", end=' ')

                except Exception as e:
                    print(f"ğŸ”´ ERRO: {str(e)}", end=' ')
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    with open(error_log_file, 'a') as f:
                        f.write(f"{timestamp}|{url}|{type(e).__name__}|{str(e)}\n")
                sleep(1)

    conn.close()
    print("\n\nâœ… EXTRAÃ‡ÃƒO CONCLUÃDA!")

def run_failed_urls(error_log_file, assuntos_file, prefeituras_file, db_file):
    if not os.path.exists(error_log_file):
        print("\nğŸ”´ Nenhum arquivo de log de erros encontrado.")
        return

    failed_urls = []
    with open(error_log_file, 'r') as f:
        for line in f:
            partes = line.strip().split('|')
            if len(partes) >= 2:
                failed_urls.append(partes[1])

    if not failed_urls:
        print("\nâœ… Nenhuma URL com erro para reprocessar.")
        return

    print(f"\nğŸ”§ Reprocessando {len(failed_urls)} URLs com erro")
    session = get_retry_session()
    prefeituras = load_prefeituras(prefeituras_file)
    assuntos = load_assuntos(assuntos_file)
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()
    success_count = 0
    temp_error_file = error_log_file + ".temp"

    for url in failed_urls:
        try:
            print(f"ğŸ” Tentando novamente: {url}", end=' ', flush=True)
            url = normalizar_url(url).replace('//', '/').replace('https:/', 'https://')
            parsed = urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}"
            
            if '?' not in url:
                print("ğŸŸ¡ URL sem parÃ¢metros. Ignorando.")
                continue

            # Extrai o endpoint_name do path (parte apÃ³s /api/)
            path_parts = parsed.path.split('/')
            if 'api' in path_parts:
                api_index = path_parts.index('api')
                if api_index + 1 < len(path_parts):
                    endpoint_name = path_parts[api_index + 1].split('?')[0]
                else:
                    print("ğŸŸ¡ URL malformada. Ignorando.")
                    continue
            else:
                print("ğŸŸ¡ URL nÃ£o contÃ©m 'api'. Ignorando.")
                continue

            query_params = parsed.query
            params_dict = dict(param.split('=', 1) for param in query_params.split('&') if '=' in param)
            
            ano = int(params_dict.get('exercicio', 0))
            unidade_gestora = params_dict.get('unidadegestoraId', '')

            prefeitura_match = prefeituras[
                (prefeituras['url'].str.strip().apply(normalizar_url) == base_url) & 
                (prefeituras['unidadegestora'] == unidade_gestora)
            ]
            
            if prefeitura_match.empty:
                print("ğŸŸ¡ Prefeitura nÃ£o encontrada. Ignorando.")
                continue

            prefeitura = prefeitura_match.iloc[0]
            municipio = prefeitura['municipio']
            prefeitura_nome = prefeitura['prefeitura']

            response = session.get(url, timeout=60)
            response.raise_for_status()
            if not response.content.strip():
                print("ğŸŸ¡ Resposta vazia. Ignorando.")
                continue

            dados = response.json()
            df = pd.DataFrame(dados)

            if not df.empty:
                df['municipio'] = municipio
                df['prefeitura'] = prefeitura_nome
                df['unidadegestora'] = unidade_gestora
                df['ano'] = ano

                cursor.execute(f"PRAGMA table_info({endpoint_name})")
                existing_columns = [col[1] for col in cursor.fetchall()]

                for column in df.columns:
                    if column not in existing_columns and column != 'id':
                        col_type = 'TEXT'
                        if pd.api.types.is_numeric_dtype(df[column]):
                            col_type = 'REAL'
                        elif pd.api.types.is_integer_dtype(df[column]):
                            col_type = 'INTEGER'
                        cursor.execute(f"ALTER TABLE {endpoint_name} ADD COLUMN {column} {col_type}")
                        conn.commit()

                df.to_sql(endpoint_name, conn, if_exists='append', index=False)
                success_count += 1
                print("âœ… Sucesso")

        except Exception as e:
            print(f"ğŸ”´ Falhou novamente: {str(e)}")
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            with open(temp_error_file, 'a') as f:
                f.write(f"{timestamp}|{url}|{type(e).__name__}|{str(e)}\n")
        sleep(1)

    conn.close()
    os.replace(temp_error_file, error_log_file)
    print(f"\nâœ… ConcluÃ­do! {success_count}/{len(failed_urls)} URLs reprocessadas com sucesso.")

def save_last_run(last_run_file, ano):
    with open(last_run_file, 'w') as f:
        f.write(str(ano))

def get_last_run(last_run_file):
    if not os.path.exists(last_run_file):
        return None
    with open(last_run_file, 'r') as f:
        return int(f.read().strip())

def log_execution(log_file, message):
    timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
    with open(log_file, 'a') as f:
        f.write(f"[{timestamp}] {message}\n")

def log_execution_time(log_file, start_time):
    elapsed = time() - start_time
    minutes, seconds = divmod(elapsed, 60)
    timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
    with open(log_file, 'a') as f:
        f.write(f"[{timestamp}] Tempo de execuÃ§Ã£o: {int(minutes)} minutos e {int(seconds)} segundos\n\n")

def load_prefeituras(filename):
    try:
        return pd.read_csv(filename)
    except Exception as e:
        print(f"\nğŸ”´ ERRO ao ler arquivo de prefeituras: {str(e)}")
        return pd.DataFrame()

def load_assuntos(filename):
    try:
        df = pd.read_csv(filename)
        # Garante que os parÃ¢metros sejam strings e trata valores NaN
        df['parametros'] = df['parametros'].fillna('').astype(str)
        return df
    except Exception as e:
        print(f"\nğŸ”´ ERRO ao ler arquivo de assuntos: {str(e)}")
        return pd.DataFrame(columns=['assunto', 'parametros'])

if __name__ == "__main__":
    main()